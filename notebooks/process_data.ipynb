{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "db = client.linkedin\n",
    "collection = db.jobIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(collection.find({'label' : { '$exists': True}} )))\n",
    "df_test = pd.DataFrame(list(collection.find({'loaded': True,'label' : { '$exists': False}} )))\n",
    "df_full = pd.DataFrame(list(collection.find({})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                        _id       jobId  loaded       company  \\\n0  5efca850b4432a82d5b96daa  1666204878    True  Michael Page   \n1  5efca850b4432a82d5b96dab  1869872248    True   Amoria Bond   \n2  5efca850b4432a82d5b96dad  1907262846    True       Xquisit   \n\n                                 city  posted  applicants  applicants_per_day  \\\n0  Brussels, Brussels Region, Belgium     196          26            0.131980   \n1  Brussels, Brussels Region, Belgium       7          80           10.000000   \n2  Brussels, Brussels Region, Belgium      21          10            0.454545   \n\n                                         description   Seniority level  \\\n0  Financial Planning & Data AnalystHybrid functi...         Associate   \n1  Python DeveloperAmoria Bond is looking for a P...  Mid-Senior level   \n2  Wij zoeken géén Data Scientist of Developer vo...       Entry level   \n\n  Employment type            Job function  \\\n0       Full-time  Information Technology   \n1        Contract             Engineering   \n2       Full-time  Information Technology   \n\n                            Industries                                 title  \n0  Information Technology and Services     Financial Planning & Data Analyst  \n1               Information Technology               Senior Python Developer  \n2  Information Technology and Services  Enterprise Data Specialist / Manager  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>jobId</th>\n      <th>loaded</th>\n      <th>company</th>\n      <th>city</th>\n      <th>posted</th>\n      <th>applicants</th>\n      <th>applicants_per_day</th>\n      <th>description</th>\n      <th>Seniority level</th>\n      <th>Employment type</th>\n      <th>Job function</th>\n      <th>Industries</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5efca850b4432a82d5b96daa</td>\n      <td>1666204878</td>\n      <td>True</td>\n      <td>Michael Page</td>\n      <td>Brussels, Brussels Region, Belgium</td>\n      <td>196</td>\n      <td>26</td>\n      <td>0.131980</td>\n      <td>Financial Planning &amp; Data AnalystHybrid functi...</td>\n      <td>Associate</td>\n      <td>Full-time</td>\n      <td>Information Technology</td>\n      <td>Information Technology and Services</td>\n      <td>Financial Planning &amp; Data Analyst</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5efca850b4432a82d5b96dab</td>\n      <td>1869872248</td>\n      <td>True</td>\n      <td>Amoria Bond</td>\n      <td>Brussels, Brussels Region, Belgium</td>\n      <td>7</td>\n      <td>80</td>\n      <td>10.000000</td>\n      <td>Python DeveloperAmoria Bond is looking for a P...</td>\n      <td>Mid-Senior level</td>\n      <td>Contract</td>\n      <td>Engineering</td>\n      <td>Information Technology</td>\n      <td>Senior Python Developer</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5efca850b4432a82d5b96dad</td>\n      <td>1907262846</td>\n      <td>True</td>\n      <td>Xquisit</td>\n      <td>Brussels, Brussels Region, Belgium</td>\n      <td>21</td>\n      <td>10</td>\n      <td>0.454545</td>\n      <td>Wij zoeken géén Data Scientist of Developer vo...</td>\n      <td>Entry level</td>\n      <td>Full-time</td>\n      <td>Information Technology</td>\n      <td>Information Technology and Services</td>\n      <td>Enterprise Data Specialist / Manager</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "from portuguese_stop_words import pt_br_stopwords\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(pt_br_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                        _id       jobId  loaded      company  \\\n0  5efbc06fad92715989d1c6b7  1905005152    True     SciCrop®   \n1  5efbc06fad92715989d1c6b8  1687689775    True       Liv Up   \n2  5efbc06fad92715989d1c6b9  1866140587    True  Ame Digital   \n3  5efbc06fad92715989d1c6ba  1866231112    True    Capgemini   \n4  5efbc06fad92715989d1c6bb  1925461308    True         Dasa   \n\n                           city  posted  applicants  applicants_per_day  \\\n0  São Paulo, São Paulo, Brazil       4          10            2.000000   \n1  São Paulo, São Paulo, Brazil     168          80            0.473373   \n2  São Paulo, São Paulo, Brazil      56         178            3.122807   \n3    Barueri, São Paulo, Brazil      21          10            0.454545   \n4  São Paulo, São Paulo, Brazil       2         150           50.000000   \n\n                                         description   Seniority level  \\\n0  The ideal candidate's favorite words are learn...  Mid-Senior level   \n1  A Liv Up é a startup que está construindo a al...       Entry level   \n2  Oi, somos a Ame!Somos um fintech trabalhando p...       Entry level   \n3  Quer trabalhar em uma das empresas mais éticas...  Mid-Senior level   \n4  Job DescriptionWith innovation and entrepreneu...       Entry level   \n\n  Employment type Job function              Industries  \\\n0       Temporary  Engineering  Information Technology   \n1       Full-time  Engineering  Information Technology   \n2       Full-time  Engineering  Information Technology   \n3       Full-time      Analyst  Information Technology   \n4       Full-time  Engineering  Information Technology   \n\n                       title  label  \n0             Data Scientist      1  \n1             Data Scientist      1  \n2             Data Scientist      1  \n3  Data Scientist (Teradata)      0  \n4             Data Scientist      1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>jobId</th>\n      <th>loaded</th>\n      <th>company</th>\n      <th>city</th>\n      <th>posted</th>\n      <th>applicants</th>\n      <th>applicants_per_day</th>\n      <th>description</th>\n      <th>Seniority level</th>\n      <th>Employment type</th>\n      <th>Job function</th>\n      <th>Industries</th>\n      <th>title</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5efbc06fad92715989d1c6b7</td>\n      <td>1905005152</td>\n      <td>True</td>\n      <td>SciCrop®</td>\n      <td>São Paulo, São Paulo, Brazil</td>\n      <td>4</td>\n      <td>10</td>\n      <td>2.000000</td>\n      <td>The ideal candidate's favorite words are learn...</td>\n      <td>Mid-Senior level</td>\n      <td>Temporary</td>\n      <td>Engineering</td>\n      <td>Information Technology</td>\n      <td>Data Scientist</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5efbc06fad92715989d1c6b8</td>\n      <td>1687689775</td>\n      <td>True</td>\n      <td>Liv Up</td>\n      <td>São Paulo, São Paulo, Brazil</td>\n      <td>168</td>\n      <td>80</td>\n      <td>0.473373</td>\n      <td>A Liv Up é a startup que está construindo a al...</td>\n      <td>Entry level</td>\n      <td>Full-time</td>\n      <td>Engineering</td>\n      <td>Information Technology</td>\n      <td>Data Scientist</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5efbc06fad92715989d1c6b9</td>\n      <td>1866140587</td>\n      <td>True</td>\n      <td>Ame Digital</td>\n      <td>São Paulo, São Paulo, Brazil</td>\n      <td>56</td>\n      <td>178</td>\n      <td>3.122807</td>\n      <td>Oi, somos a Ame!Somos um fintech trabalhando p...</td>\n      <td>Entry level</td>\n      <td>Full-time</td>\n      <td>Engineering</td>\n      <td>Information Technology</td>\n      <td>Data Scientist</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5efbc06fad92715989d1c6ba</td>\n      <td>1866231112</td>\n      <td>True</td>\n      <td>Capgemini</td>\n      <td>Barueri, São Paulo, Brazil</td>\n      <td>21</td>\n      <td>10</td>\n      <td>0.454545</td>\n      <td>Quer trabalhar em uma das empresas mais éticas...</td>\n      <td>Mid-Senior level</td>\n      <td>Full-time</td>\n      <td>Analyst</td>\n      <td>Information Technology</td>\n      <td>Data Scientist (Teradata)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5efbc06fad92715989d1c6bb</td>\n      <td>1925461308</td>\n      <td>True</td>\n      <td>Dasa</td>\n      <td>São Paulo, São Paulo, Brazil</td>\n      <td>2</td>\n      <td>150</td>\n      <td>50.000000</td>\n      <td>Job DescriptionWith innovation and entrepreneu...</td>\n      <td>Entry level</td>\n      <td>Full-time</td>\n      <td>Engineering</td>\n      <td>Information Technology</td>\n      <td>Data Scientist</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df['Description Length'] = df['description'].apply(len)\n",
    "df_test['Description Length'] = df_test['description'].apply(len)\n",
    "\n",
    "X = df.drop(columns=['label'])\n",
    "y = df[['label']]\n",
    "\n",
    "usedFeatures = ['applicants', 'applicants_per_day', 'Description Length']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "final_features_train = [X_train[usedFeatures]]\n",
    "final_features_val = [X_val[usedFeatures]]\n",
    "final_features_test = [df_test[usedFeatures]]\n",
    "\n",
    "final_vects_train = []\n",
    "final_vects_val = []\n",
    "final_vects_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seniority_train = pd.get_dummies(X_train['Seniority level'])\n",
    "seniority_val = pd.get_dummies(X_val['Seniority level'])\n",
    "seniority_test = pd.get_dummies(df_test['Seniority level'])\n",
    "\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set( seniority_train.columns ) - set( seniority_val.columns )\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for c in missing_cols:\n",
    "    seniority_val[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "seniority_val = seniority_val[seniority_train.columns]\n",
    "\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set( seniority_train.columns ) - set( seniority_test.columns )\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for c in missing_cols:\n",
    "    seniority_test[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "seniority_test = seniority_test[seniority_train.columns]\n",
    "\n",
    "final_features_train.append(seniority_train)\n",
    "final_features_val.append(seniority_val)\n",
    "final_features_test.append(seniority_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extractor import get_ohe_features\n",
    "\n",
    "test = get_ohe_features(X_train, 'Seniority level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     Associate  Director  Entry level  Executive  Internship  \\\n467          0         0            1          0           0   \n18           0         0            1          0           0   \n264          0         0            0          0           1   \n302          1         0            0          0           0   \n274          0         0            1          0           0   \n..         ...       ...          ...        ...         ...   \n334          0         0            1          0           0   \n481          0         1            0          0           0   \n425          0         0            1          0           0   \n279          0         0            1          0           0   \n202          0         0            0          0           1   \n\n     Mid-Senior level  Not Applicable  \n467                 0               0  \n18                  0               0  \n264                 0               0  \n302                 0               0  \n274                 0               0  \n..                ...             ...  \n334                 0               0  \n481                 0               0  \n425                 0               0  \n279                 0               0  \n202                 0               0  \n\n[386 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Associate</th>\n      <th>Director</th>\n      <th>Entry level</th>\n      <th>Executive</th>\n      <th>Internship</th>\n      <th>Mid-Senior level</th>\n      <th>Not Applicable</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>467</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>264</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>274</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>334</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>481</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>425</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>202</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>386 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['Information Technology', 'Internet', 'Science',\n       'Information Technology and Services', 'Real Estate',\n       'Financial Services', 'Marketing and Advertising', 'Engineering',\n       'Supply Chain', 'Information Services',\n       'Health, Wellness and Fitness', 'Computer Software',\n       'Education Management', 'Chemicals', 'Sales', 'Strategy/Planning',\n       'Analyst', 'Training', 'Product Management',\n       'Management Consulting', 'Staffing and Recruiting', 'Advertising',\n       'Paper & Forest Products', 'Market Research',\n       'Transportation/Trucking/Railroad', 'Art/Creative',\n       'Telecommunications', 'Pharmaceuticals', 'Higher Education',\n       'Research', 'Consulting', 'Writing/Editing',\n       'Hospital & Health Care', 'Manufacturing', 'General Business',\n       'Banking', 'Electrical/Electronic Manufacturing',\n       'Food & Beverages', 'Retail', 'Marketing', 'Public Relations',\n       'Apparel & Fashion', 'Computer Hardware', 'Design', nan,\n       'Medical Devices', 'Finance', 'Logistics and Supply Chain',\n       'Business Development', 'Customer Service', 'Accounting',\n       'Construction', 'Distribution', 'Food Production', 'Automotive',\n       'Leisure, Travel & Tourism', 'Management', 'Quality Assurance',\n       'Health Care Provider', 'Environmental Services',\n       'Human Resources', 'Mechanical or Industrial Engineering',\n       'Biotechnology', 'Consumer Electronics', 'Accounting/Auditing',\n       'Oil & Energy', 'Insurance', 'Administrative', 'Online Media',\n       'Farming', 'Cosmetics', 'Hospitality', 'Restaurants',\n       'Consumer Goods', 'Other', 'Utilities', 'Photography',\n       'Nonprofit Organization Management', 'Renewables & Environment',\n       'Supermarkets', 'Project Management', 'Entertainment', 'Music',\n       'Government Administration', 'Packaging and Containers',\n       'Civil Engineering', 'Media Production'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "df_full['Industries'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_type_train = pd.get_dummies(X_train['Employment type'])\n",
    "emp_type_val = pd.get_dummies(X_val['Employment type'])\n",
    "emp_type_test = pd.get_dummies(df_test['Employment type'])\n",
    "\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set( emp_type_train.columns ) - set( emp_type_val.columns )\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for c in missing_cols:\n",
    "    emp_type_val[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "emp_type_val = emp_type_val[emp_type_train.columns]\n",
    "\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set( emp_type_train.columns ) - set( emp_type_test.columns )\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for c in missing_cols:\n",
    "    emp_type_test[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "emp_type_test = emp_type_test[emp_type_train.columns]\n",
    "\n",
    "final_features_train.append(emp_type_train)\n",
    "final_features_val.append(emp_type_val)\n",
    "final_features_test.append(emp_type_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_function_columns = ['Administrative', 'Analyst', 'Business Development', 'Consulting',\n",
    "       'Design', 'Education', 'Engineering', 'Finance', 'Health Care Provider',\n",
    "       'Human Resources', 'Information Technology', 'Management', 'Marketing',\n",
    "       'Other', 'Product Management', 'Project Management',\n",
    "       'Quality Assurance', 'Research', 'Sales', 'Science',\n",
    "       'Strategy/Planning']\n",
    "\n",
    "job_function_train = pd.get_dummies(X_train['Job function'])\n",
    "job_function_val = pd.get_dummies(X_val['Job function'])\n",
    "job_function_test = pd.get_dummies(df_test['Job function'])\n",
    "\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set( job_function_train.columns ) - set( job_function_val.columns )\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for c in missing_cols:\n",
    "    job_function_val[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "job_function_val = job_function_val[job_function_train.columns]\n",
    "\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set( job_function_train.columns ) - set( job_function_test.columns )\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for c in missing_cols:\n",
    "    job_function_test[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "job_function_test = job_function_test[job_function_train.columns]\n",
    "\n",
    "final_features_train.append(job_function_train)\n",
    "final_features_val.append(job_function_val)\n",
    "final_features_test.append(job_function_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "industries_columns = ['Analyst', 'Apparel & Fashion', 'Art/Creative', 'Business Development',\n",
    "       'Chemicals', 'Computer Hardware', 'Computer Software', 'Consulting',\n",
    "       'Customer Service', 'Design', 'Education Management',\n",
    "       'Electrical/Electronic Manufacturing', 'Engineering', 'Finance',\n",
    "       'Financial Services', 'Food & Beverages',\n",
    "       'Health, Wellness and Fitness', 'Hospital & Health Care',\n",
    "       'Information Services', 'Information Technology',\n",
    "       'Information Technology and Services', 'Internet',\n",
    "       'Logistics and Supply Chain', 'Manufacturing', 'Market Research',\n",
    "       'Marketing', 'Marketing and Advertising', 'Medical Devices',\n",
    "       'Paper & Forest Products', 'Pharmaceuticals', 'Research', 'Retail',\n",
    "       'Sales', 'Science', 'Staffing and Recruiting', 'Strategy/Planning',\n",
    "       'Telecommunications', 'Training', 'Writing/Editing']\n",
    "\n",
    "industries_train = pd.get_dummies(X_train['Industries'])\n",
    "industries_val = pd.get_dummies(X_val['Industries'])\n",
    "industries_test = pd.get_dummies(df_test['Industries'])\n",
    "\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set( industries_train.columns ) - set( industries_val.columns )\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for c in missing_cols:\n",
    "    industries_val[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "industries_val = industries_val[industries_train.columns]\n",
    "\n",
    "# Get missing columns in the training test\n",
    "missing_cols = set( industries_train.columns ) - set( industries_test.columns )\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for c in missing_cols:\n",
    "    industries_test[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "industries_test = industries_test[industries_train.columns]\n",
    "\n",
    "final_features_train.append(industries_train)\n",
    "final_features_val.append(industries_val)\n",
    "final_features_test.append(industries_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(386, 81)\n"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "title_vec = TfidfVectorizer(min_df=4, ngram_range=(1,2), stop_words=stop_words)\n",
    "title_bow_train = title_vec.fit_transform(X_train['title'])\n",
    "title_bow_val = title_vec.transform(X_val['title'])\n",
    "title_bow_test = title_vec.transform(df_test['title'])\n",
    "\n",
    "print(title_bow_train.shape)\n",
    "\n",
    "final_vects_train.append(title_bow_train)\n",
    "final_vects_val.append(title_bow_val)\n",
    "final_vects_test.append(title_bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(386, 7267)\n"
    }
   ],
   "source": [
    "desc_vec = TfidfVectorizer(min_df=4, ngram_range=(1,3), stop_words=stop_words)\n",
    "desc_bow_train = desc_vec.fit_transform(X_train['description'])\n",
    "desc_bow_val = desc_vec.transform(X_val['description'])\n",
    "desc_bow_test = desc_vec.transform(df_test['description'])\n",
    "\n",
    "print(desc_bow_train.shape)\n",
    "\n",
    "final_vects_train.append(desc_bow_train)\n",
    "final_vects_val.append(desc_bow_val)\n",
    "final_vects_test.append(desc_bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "X_train_full = hstack(final_features_train + final_vects_train)\n",
    "X_val_full = hstack(final_features_val + final_vects_val)\n",
    "X_test_full = hstack(final_features_test + final_vects_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=10, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n                       n_jobs=-1, oob_score=False, random_state=0, verbose=0,\n                       warm_start=False)"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "mdl = RandomForestClassifier(n_estimators=1000, random_state=0, class_weight=\"balanced\", n_jobs=-1, min_samples_leaf=10)\n",
    "mdl.fit(X_train_full, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Precision: 51.09%\tAUC: 0.799\n"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "p = mdl.predict_proba(X_val_full)[:, 1]\n",
    "\n",
    "precision = average_precision_score(y_val, p)\n",
    "auc = roc_auc_score(y_val, p)\n",
    "\n",
    "print(\"Precision: {:.2f}%\\tAUC: {:.3f}\".format(precision*100, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision: 68.71%\tAUC: 0.900 - title_vec = (min_df=3, ngram_range=(1,2) desc_vec =(min_df=4, ngram_range=(1,3)\n",
    "# Precision: 71.35%\tAUC: 0.875 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mdl.predict_proba(X_test_full)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['p'] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [_id, jobId, loaded, company, city, posted, applicants, applicants_per_day, description, Seniority level, Employment type, Job function, Industries, title, Description Length, p]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>jobId</th>\n      <th>loaded</th>\n      <th>company</th>\n      <th>city</th>\n      <th>posted</th>\n      <th>applicants</th>\n      <th>applicants_per_day</th>\n      <th>description</th>\n      <th>Seniority level</th>\n      <th>Employment type</th>\n      <th>Job function</th>\n      <th>Industries</th>\n      <th>title</th>\n      <th>Description Length</th>\n      <th>p</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "df_test.sort_values('p', ascending=False)[df_test['p'] > 0.8].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n               colsample_bytree=1.0, importance_type='split', learning_rate=0.1,\n               max_depth=-1, min_child_samples=20, min_child_weight=0.001,\n               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n               objective=None, random_state=0, reg_alpha=0.0, reg_lambda=0.0,\n               silent=True, subsample=1.0, subsample_for_bin=200000,\n               subsample_freq=0)"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "mdl = LGBMClassifier(random_state=0, class_weight=\"balanced\", n_jobs=-1)\n",
    "mdl.fit(X_train_full, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Precision: 55.83%\tAUC: 0.788\n"
    }
   ],
   "source": [
    "p = mdl.predict_proba(X_val_full)[:, 1]\n",
    "\n",
    "precision = average_precision_score(y_val, p)\n",
    "auc = roc_auc_score(y_val, p)\n",
    "\n",
    "print(\"Precision: {:.2f}%\\tAUC: {:.3f}\".format(precision*100, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import forest_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iteration No: 1 started. Evaluating function at random point.\n[0.0015917412074366864, 1, 1, 0.7162891223936204, 0.07362894136443292, 147, 7, 2, 3, 5]\n0.7962607861936721\nIteration No: 1 ended. Evaluation done at random point.\nTime taken: 3.0815\nFunction value obtained: -0.4756\nCurrent minimum: -0.4756\nIteration No: 2 started. Evaluating function at random point.\n[0.004405577997314528, 5, 16, 0.5222531571218747, 0.37454048985593646, 188, 2, 2, 2, 4]\n0.783796740172579\nIteration No: 2 ended. Evaluation done at random point.\nTime taken: 2.2665\nFunction value obtained: -0.4708\nCurrent minimum: -0.4756\nIteration No: 3 started. Evaluating function at random point.\n[0.004088470709702419, 4, 11, 0.10800798914439425, 0.6744232993630378, 828, 8, 1, 10, 5]\n0.7694151486097794\nIteration No: 3 ended. Evaluation done at random point.\nTime taken: 3.0565\nFunction value obtained: -0.4446\nCurrent minimum: -0.4756\nIteration No: 4 started. Evaluating function at random point.\n[0.07813279834700627, 3, 2, 0.19464742766319365, 0.8826510032812228, 610, 8, 3, 6, 1]\n0.8042505592841164\nIteration No: 4 ended. Evaluation done at random point.\nTime taken: 10.2905\nFunction value obtained: -0.5473\nCurrent minimum: -0.5473\nIteration No: 5 started. Evaluating function at random point.\n[0.0047316685280135665, 7, 19, 0.9562132227514879, 0.8732796806976341, 356, 3, 2, 5, 2]\n0.7849153084052414\nIteration No: 5 ended. Evaluation done at random point.\nTime taken: 3.2105\nFunction value obtained: -0.4543\nCurrent minimum: -0.5473\nIteration No: 6 started. Evaluating function at random point.\n[0.014557131367835664, 5, 6, 0.42336638532112275, 0.8929732271840062, 294, 3, 2, 5, 5]\n0.8039309683604985\nIteration No: 6 ended. Evaluation done at random point.\nTime taken: 6.6130\nFunction value obtained: -0.5623\nCurrent minimum: -0.5623\nIteration No: 7 started. Evaluating function at random point.\n[0.013934092462665066, 5, 12, 0.9336374918541379, 0.11878239609587547, 219, 4, 1, 3, 1]\n0.7994566954298498\nIteration No: 7 ended. Evaluation done at random point.\nTime taken: 2.2680\nFunction value obtained: -0.5468\nCurrent minimum: -0.5623\nIteration No: 8 started. Evaluating function at random point.\n[0.001008727023814221, 5, 13, 0.2597057890933073, 0.80995750220523, 475, 3, 3, 10, 5]\n0.7842761265580057\nIteration No: 8 ended. Evaluation done at random point.\nTime taken: 4.7575\nFunction value obtained: -0.4677\nCurrent minimum: -0.5623\nIteration No: 9 started. Evaluating function at random point.\n[0.0023639962125898695, 3, 17, 0.9333677435028198, 0.08925954433399245, 191, 6, 1, 7, 1]\n0.7747682965803772\nIteration No: 9 ended. Evaluation done at random point.\nTime taken: 1.8475\nFunction value obtained: -0.4690\nCurrent minimum: -0.5623\nIteration No: 10 started. Evaluating function at random point.\n[0.003199978657532326, 4, 15, 0.9323373298590059, 0.5354537044949594, 701, 2, 1, 10, 1]\n0.7863534675615212\nIteration No: 10 ended. Evaluation done at random point.\nTime taken: 7.8790\nFunction value obtained: -0.4841\nCurrent minimum: -0.5623\nIteration No: 11 started. Evaluating function at random point.\n[0.0019020921880005457, 3, 8, 0.3927664725025251, 0.3203310575638233, 422, 2, 1, 9, 5]\n0.7829977628635347\nIteration No: 11 ended. Evaluation done at random point.\nTime taken: 7.0680\nFunction value obtained: -0.4960\nCurrent minimum: -0.5623\nIteration No: 12 started. Evaluating function at random point.\n[0.024328898182952075, 9, 2, 0.6143438561755443, 0.08483453277017063, 681, 5, 2, 2, 5]\n0.7983381271971877\nIteration No: 12 ended. Evaluation done at random point.\nTime taken: 57.5485\nFunction value obtained: -0.5720\nCurrent minimum: -0.5720\nIteration No: 13 started. Evaluating function at random point.\n[0.0026466354463825868, 4, 12, 0.8669821653532319, 0.8987800176198864, 424, 9, 2, 7, 4]\n0.781240012783637\nIteration No: 13 ended. Evaluation done at random point.\nTime taken: 9.2761\nFunction value obtained: -0.4624\nCurrent minimum: -0.5720\nIteration No: 14 started. Evaluating function at random point.\n[0.02962182372816251, 4, 1, 0.5776847476312866, 0.5523244942642205, 932, 8, 1, 8, 3]\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-6fe6105964ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m           (1,5)] # ngram_range desc\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforest_minimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtune_lgbm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m255479\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_random_starts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\forest.py\u001b[0m in \u001b[0;36mforest_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, x0, y0, random_state, verbose, callback, n_points, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    174\u001b[0m                          \u001b[0mxi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkappa\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkappa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m                          \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macq_optimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sampling\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m                          model_queue_size=model_queue_size)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[0mnext_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-6fe6105964ae>\u001b[0m in \u001b[0;36mtune_lgbm\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     37\u001b[0m                          \u001b[0mcolsample_bytree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolsample_bytree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbagging_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                          class_weight=\"balanced\", n_jobs=6)\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_full\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_full\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    803\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m                                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    806\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    598\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1976\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1978\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def tune_lgbm(params):\n",
    "    print(params)\n",
    "    lr = params[0]\n",
    "    max_depth = params[1]\n",
    "    min_child_samples = params[2]\n",
    "    subsample = params[3]\n",
    "    colsample_bytree = params[4]\n",
    "    n_estimators = params[5]\n",
    "    \n",
    "    min_df = params[6]\n",
    "    ngram_range = (1, params[7])\n",
    "    \n",
    "    min_df_desc = params[8]\n",
    "    ngram_range_desc = (1, params[9])\n",
    "    \n",
    "    title_vec = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range, stop_words=stop_words)\n",
    "    title_bow_train = title_vec.fit_transform(X_train['title'])\n",
    "    title_bow_val = title_vec.transform(X_val['title'])\n",
    "    \n",
    "    final_features_train.append(title_bow_train)\n",
    "    final_features_val.append(title_bow_val)\n",
    "\n",
    "    desc_vec = TfidfVectorizer(min_df=min_df_desc, ngram_range=ngram_range_desc, stop_words=stop_words)\n",
    "    desc_bow_train = desc_vec.fit_transform(X_train['description'])\n",
    "    desc_bow_val = desc_vec.transform(X_val['description'])\n",
    "\n",
    "    final_features_train.append(desc_bow_train)\n",
    "    final_features_val.append(desc_bow_val)\n",
    "\n",
    "    \n",
    "    \n",
    "    X_train_full = hstack(final_features_train)\n",
    "    X_val_full = hstack(final_features_val)\n",
    "\n",
    "    mdl = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth, \n",
    "                         min_child_samples=min_child_samples, subsample=subsample,\n",
    "                         colsample_bytree=colsample_bytree, bagging_freq=1,n_estimators=n_estimators, random_state=0, \n",
    "                         class_weight=\"balanced\", n_jobs=6)\n",
    "    mdl.fit(X_train_full, y_train)\n",
    "    \n",
    "    p = mdl.predict_proba(X_val_full)[:, 1]\n",
    "    \n",
    "    print(roc_auc_score(y_val, p))\n",
    "    \n",
    "    return -average_precision_score(y_val, p)\n",
    "\n",
    "\n",
    "space = [(1e-3, 1e-1, 'log-uniform'), # lr\n",
    "          (1, 10), # max_depth\n",
    "          (1, 20), # min_child_samples\n",
    "          (0.05, 1.), # subsample\n",
    "          (0.05, 1.), # colsample_bytree\n",
    "          (100,1000), # n_estimators\n",
    "          (2,10), # min_df title\n",
    "          (1,3), # ngram_range title\n",
    "          (2,10), # min_df desc\n",
    "          (1,5)] # ngram_range desc\n",
    "\n",
    "res = forest_minimize(tune_lgbm, space, random_state=255479, n_random_starts=20, n_calls=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.005677937885284806,\n 4,\n 1,\n 0.9591262059674839,\n 0.794014754551486,\n 780,\n 9,\n 1,\n 5,\n 2]"
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iteration No: 1 started. Evaluating function at random point.\n[0.0015917412074366864, 1, 1, 0.7162891223936204, 0.07362894136443292, 147, 7, 2, 3, 5]\n"
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "no supported conversion for types: (dtype('float64'), dtype('uint8'), dtype('int64'), dtype('int64'), dtype('O'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'))",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-6fe6105964ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m           (1,5)] # ngram_range desc\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforest_minimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtune_lgbm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m255479\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_random_starts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\forest.py\u001b[0m in \u001b[0;36mforest_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, x0, y0, random_state, verbose, callback, n_points, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    174\u001b[0m                          \u001b[0mxi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkappa\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkappa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m                          \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macq_optimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"sampling\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m                          model_queue_size=model_queue_size)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[0mnext_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-92-6fe6105964ae>\u001b[0m in \u001b[0;36mtune_lgbm\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mX_train_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_features_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mX_val_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_features_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     mdl = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth, \n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\construct.py\u001b[0m in \u001b[0;36mhstack\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \"\"\"\n\u001b[1;32m--> 465\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\construct.py\u001b[0m in \u001b[0;36mbmat\u001b[1;34m(blocks, format, dtype)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m         \u001b[0mall_dtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mblock_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mall_dtypes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mall_dtypes\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mrow_offsets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrow_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no supported conversion for types: %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no supported conversion for types: (dtype('float64'), dtype('uint8'), dtype('int64'), dtype('int64'), dtype('O'), dtype('float64'), dtype('float64'), dtype('float64'), dtype('float64'))"
     ]
    }
   ],
   "source": [
    "def tune_lgbm(params):\n",
    "    print(params)\n",
    "    lr = params[0]\n",
    "    max_depth = params[1]\n",
    "    min_child_samples = params[2]\n",
    "    subsample = params[3]\n",
    "    colsample_bytree = params[4]\n",
    "    n_estimators = params[5]\n",
    "    \n",
    "    min_df = params[6]\n",
    "    ngram_range = (1, params[7])\n",
    "    \n",
    "    min_df_desc = params[8]\n",
    "    ngram_range_desc = (1, params[9])\n",
    "    \n",
    "    title_vec = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range, stop_words=stop_words)\n",
    "    title_bow_train = title_vec.fit_transform(X_train['title'])\n",
    "    title_bow_val = title_vec.transform(X_val['title'])\n",
    "    \n",
    "    final_features_train.append(title_bow_train)\n",
    "    final_features_val.append(title_bow_val)\n",
    "\n",
    "    desc_vec = TfidfVectorizer(min_df=min_df_desc, ngram_range=ngram_range_desc, stop_words=stop_words)\n",
    "    desc_bow_train = desc_vec.fit_transform(X_train['description'])\n",
    "    desc_bow_val = desc_vec.transform(X_val['description'])\n",
    "\n",
    "    final_features_train.append(desc_bow_train)\n",
    "    final_features_val.append(desc_bow_val)\n",
    "\n",
    "    \n",
    "    \n",
    "    X_train_full = hstack(final_features_train)\n",
    "    X_val_full = hstack(final_features_val)\n",
    "\n",
    "    mdl = LGBMClassifier(learning_rate=lr, num_leaves=2 ** max_depth, max_depth=max_depth, \n",
    "                         min_child_samples=min_child_samples, subsample=subsample,\n",
    "                         colsample_bytree=colsample_bytree, bagging_freq=1,n_estimators=n_estimators, random_state=0, \n",
    "                         class_weight=\"balanced\", n_jobs=6)\n",
    "    mdl.fit(X_train_full, y_train)\n",
    "    \n",
    "    p = mdl.predict_proba(X_val_full)[:, 1]\n",
    "    \n",
    "    print(roc_auc_score(y_val, p))\n",
    "    \n",
    "    return -average_precision_score(y_val, p)\n",
    "\n",
    "\n",
    "space = [(1e-3, 1e-1, 'log-uniform'), # lr\n",
    "          (1, 10), # max_depth\n",
    "          (1, 20), # min_child_samples\n",
    "          (0.05, 1.), # subsample\n",
    "          (0.05, 1.), # colsample_bytree\n",
    "          (100,1000), # n_estimators\n",
    "          (2,10), # min_df title\n",
    "          (1,3), # ngram_range title\n",
    "          (2,10), # min_df desc\n",
    "          (1,5)] # ngram_range desc\n",
    "\n",
    "res = forest_minimize(tune_lgbm, space, random_state=255479, n_random_starts=20, n_calls=50, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}